<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pipeline Parallelism | SysML@ICL</title><link>https://sysml.doc.ic.ac.uk/tag/pipeline-parallelism/</link><atom:link href="https://sysml.doc.ic.ac.uk/tag/pipeline-parallelism/index.xml" rel="self" type="application/rss+xml"/><description>Pipeline Parallelism</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 19 Jan 2023 10:30:00 +0000</lastBuildDate><image><url>https://sysml.doc.ic.ac.uk/media/logo_hu0e4a96b537c97ee56dff564995bc792a_102878_300x300_fit_lanczos_3.png</url><title>Pipeline Parallelism</title><link>https://sysml.doc.ic.ac.uk/tag/pipeline-parallelism/</link></image><item><title>Reading Group Session #3</title><link>https://sysml.doc.ic.ac.uk/event/reading3/</link><pubDate>Thu, 19 Jan 2023 10:30:00 +0000</pubDate><guid>https://sysml.doc.ic.ac.uk/event/reading3/</guid><description>&lt;h1 id="pathways">Pathways&lt;/h1>
&lt;p>&lt;a href="https://proceedings.mlsys.org/paper/2022/hash/98dce83da57b0395e163467c9dae521b-Abstract.html" target="_blank" rel="noopener">Paper Link&lt;/a>, SysML'22&lt;/p>
&lt;p>&lt;strong>Paper Abstract:&lt;/strong>&lt;/p>
&lt;p>We present the design of a new large scale orchestration layer for accelerators. Our system, Pathways, is explicitly designed to enable exploration of new systems and ML research ideas, while retaining state of the art performance for current models. Pathways uses a sharded dataflow graph of asynchronous operators that consume and produce futures, and efficiently gang-schedules heterogeneous parallel computations on thousands of accelerators while coordinating data transfers over their dedicated interconnects. Pathways makes use of a novel asynchronous distributed dataflow design that lets the control plane execute in parallel despite dependencies in the data plane. This design, with careful engineering, allows Pathways to adopt a single-controller model that makes it easier to express complex new parallelism patterns. We demonstrate that Pathways can achieve performance parity (~100% accelerator utilization) with state-of-the-art systems when running SPMD computations over 2048 TPUs, while also delivering throughput comparable to the SPMD case for Transformer models that are pipelined across 16 stages, or sharded across two islands of accelerators connected over a data center network.&lt;/p>
&lt;h1 id="discussion-notes">Discussion Notes&lt;/h1>
&lt;p>TBD&lt;/p></description></item><item><title>Seminar #5 - Colin Unger - Unity (OSDI'22)</title><link>https://sysml.doc.ic.ac.uk/event/seminar5/</link><pubDate>Thu, 08 Sep 2022 10:30:00 +0000</pubDate><guid>https://sysml.doc.ic.ac.uk/event/seminar5/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://imperial-ac-uk.zoom.us/j/96569969529?pwd=anprUE80SkFvcFh5ajE4OG45V1J1Zz09" class="btn btn-primary px-3 py-3">Join Zoom Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;div style="text-align: center;">
&lt;a title="Add to Calendar" class="addeventatc" data-id="uf14485709" href="https://www.addevent.com/event/uf14485709" target="_blank">Add to Calendar&lt;/a>
&lt;script type="text/javascript" src="https://cdn.addevent.com/libs/atc/1.6.1/atc.min.js" async defer>&lt;/script>
&lt;/div>
&lt;h1 id="speaker-bio">Speaker Bio&lt;/h1>
&lt;p>Colin Unger is a second year PhD student at Stanford advised by Alex Aiken. He received his bachelor&amp;rsquo;s degree from UC Santa Barbara, where he worked with Giovanni Vigna and Christopher Kruegel on binary analysis. He is broadly interested in compilers, program analysis, and optimization, especially in emerging applications, and is currently focused on hardware-aware optimization of deep learning workloads.&lt;/p></description></item><item><title>Seminar #3 - Abhinav Jangda - CoCoNet (ASPLOS'22)</title><link>https://sysml.doc.ic.ac.uk/event/seminar3/</link><pubDate>Thu, 28 Jul 2022 10:30:00 +0000</pubDate><guid>https://sysml.doc.ic.ac.uk/event/seminar3/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://imperial-ac-uk.zoom.us/j/91933548102?pwd=RFhsc1R0NWJldDFzNUZiMUU0dmd4dz09" class="btn btn-primary px-3 py-3">Join Zoom Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;div style="text-align: center;">
&lt;a title="Add to Calendar" class="addeventatc" data-id="ZE14485670" href="https://www.addevent.com/event/ZE14485670" target="_blank">Add to Calendar&lt;/a>
&lt;script type="text/javascript" src="https://cdn.addevent.com/libs/atc/1.6.1/atc.min.js" async defer>&lt;/script>
&lt;/div>
&lt;h1 id="speaker-bio">Speaker Bio&lt;/h1>
&lt;p>Abhinav Jangda is a PhD student at the University of Massachusetts
Amherst and will join Microsoft Research in Fall 2022. His research
focuses on developing programming language abstractions and compilation
techniques to help programmers leverage large scale systems
efficiently. His work was invited for an article in USENIX :login;, has
received an ACM SIGPLAN Distinguished Paper Award at OOPSLA, and a Best
Paper Award at PACT.&lt;/p></description></item><item><title>Reading Group Session #1</title><link>https://sysml.doc.ic.ac.uk/event/reading1/</link><pubDate>Thu, 09 Jun 2022 10:30:00 +0000</pubDate><guid>https://sysml.doc.ic.ac.uk/event/reading1/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://teams.microsoft.com/l/meetup-join/19%3aLiP6Evh3ssJQ3g41q8vAsBNwwOFTzp7d_qq1y7oTo7A1%40thread.tacv2/1654597085925?context=%7b%22Tid%22%3a%222b897507-ee8c-4575-830b-4f8267c3d307%22%2c%22Oid%22%3a%228d261fd5-be8f-44eb-b630-d5b230fc5ec3%22%7d" class="btn btn-primary px-3 py-3">Join Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="papers">Papers&lt;/h1>
&lt;p>Papers covered will be:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://ieeexplore.ieee.org/iel7/71/9497774/09472938.pdf" target="_blank" rel="noopener">vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training&lt;/a>, TPDS'21&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/pdf/2201.12023" target="_blank" rel="noopener">Alpa: Automating Inter-and Intra-Operator Parallelism for Distributed Deep Learning&lt;/a>, OSDI'22&lt;/li>
&lt;/ol>
&lt;h1 id="discussion-notes">Discussion Notes&lt;/h1>
&lt;p>In these discussion notes we attempt to summarize points made during the discussion on possible future directions.&lt;/p>
&lt;h2 id="vpipe">vPipe&lt;/h2>
&lt;h3 id="online-partitioning">Online partitioning&lt;/h3>
&lt;p>vPipes justification for the need for an online repartitioning algorithm is Neural Architecture Search (NAS).
Very few systems are using online partitioning nowadays. The question is, is there a need for them?
What are other motivating reasons for online partitioning?&lt;/p>
&lt;ul>
&lt;li>To deal with failures&lt;/li>
&lt;li>To support elasticity&lt;/li>
&lt;li>NAS&lt;/li>
&lt;li>Dynamic networks&lt;/li>
&lt;/ul>
&lt;p>In short, any source of dynamism in the training is justifiable.
What are other sources of dynamism in training?&lt;/p>
&lt;h3 id="pcie-usage">PCIe Usage&lt;/h3>
&lt;p>In vPipe PCIe is shared by swapping and inter-host activation communication.
The algorithm which decides the swap-recompute plan attempts to fill all the PCIe bandwidth but ignores activation communication traffic.
Is this optimal? Won&amp;rsquo;t this cause stalls by oversubscribing the PCIe bus?
Still, vPipe prioritizes inter-host activation communication.&lt;/p>
&lt;h2 id="alpa">Alpa&lt;/h2>
&lt;h3 id="device-meshes">Device Meshes&lt;/h3>
&lt;p>Alpa maps computations to a 2D mesh of devices. This seems to be due to the fact
that there are 2 layers in the device hierarchy, intra-host and inter-host,
where communication intra-host is faster than inter-host.
If there were a third level in this hierarchy, perhaps a 3D mesh of devices would make sense.&lt;/p>
&lt;h2 id="both-papers">Both papers&lt;/h2>
&lt;p>We noticed that both papers attempt to solve the NP-Complete task of parallelizing
a computational graph across several devices for optimal performance.
This task is too difficult to solve directly.
To tackle this, both papers use a decomposition approach, instead solving two subproblems optimally:&lt;/p>
&lt;ul>
&lt;li>Alpa first uses inter-op parallelism, then intra-op parallelism on each stage.&lt;/li>
&lt;li>vPipe first uses inter-op parallelism, then computes a swap/recompute plan for each stage.&lt;/li>
&lt;/ul>
&lt;p>Why can&amp;rsquo;t it be solved directly? Is it simply too large a search problem?
Are we losing something by not solving the original problem optimally?&lt;/p>
&lt;h3 id="heterogeneous-clusters">Heterogeneous Clusters&lt;/h3>
&lt;p>Heterogeneous clusters are a reality in several organizations which over time accumulate several generations of accelerators.
Furthermore, CPUs are a largely unused resource that is available.
Both papers, and other systems, generally target homogeneous clusters only.
We believe there is space for novel systems targeting Heterogeneous clusters, though the problem of partitioning and parallelizing becomes more difficult.&lt;/p></description></item></channel></rss>