<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DL Training | SysML@ICL</title><link>https://sysml-icl.github.io/tag/dl-training/</link><atom:link href="https://sysml-icl.github.io/tag/dl-training/index.xml" rel="self" type="application/rss+xml"/><description>DL Training</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 28 Jul 2022 10:30:00 +0000</lastBuildDate><image><url>https://sysml-icl.github.io/media/logo_hu0e4a96b537c97ee56dff564995bc792a_102878_300x300_fit_lanczos_3.png</url><title>DL Training</title><link>https://sysml-icl.github.io/tag/dl-training/</link></image><item><title>Seminar #3 - Abhinav Jangda - CoCoNet (ASPLOS'22)</title><link>https://sysml-icl.github.io/event/seminar3/</link><pubDate>Thu, 28 Jul 2022 10:30:00 +0000</pubDate><guid>https://sysml-icl.github.io/event/seminar3/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://teams.microsoft.com/l/meetup-join/19%3aLiP6Evh3ssJQ3g41q8vAsBNwwOFTzp7d_qq1y7oTo7A1%40thread.tacv2/1654597085925?context=%7b%22Tid%22%3a%222b897507-ee8c-4575-830b-4f8267c3d307%22%2c%22Oid%22%3a%228d261fd5-be8f-44eb-b630-d5b230fc5ec3%22%7d" class="btn btn-primary px-3 py-3">Join Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="speaker-bio">Speaker Bio&lt;/h1>
&lt;p>Abhinav Jangda is a PhD student at the University of Massachusetts
Amherst and will join Microsoft Research in Fall 2022. His research
focuses on developing programming language abstractions and compilation
techniques to help programmers leverage large scale systems
efficiently. His work was invited for an article in USENIX :login;, has
received an ACM SIGPLAN Distinguished Paper Award at OOPSLA, and a Best
Paper Award at PACT.&lt;/p></description></item><item><title>Seminar #2 - Alexander Renz-Wieland - NuPS (SIGMOD'22)</title><link>https://sysml-icl.github.io/event/seminar2/</link><pubDate>Thu, 21 Jul 2022 10:30:00 +0000</pubDate><guid>https://sysml-icl.github.io/event/seminar2/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://teams.microsoft.com/l/meetup-join/19%3aLiP6Evh3ssJQ3g41q8vAsBNwwOFTzp7d_qq1y7oTo7A1%40thread.tacv2/1654597085925?context=%7b%22Tid%22%3a%222b897507-ee8c-4575-830b-4f8267c3d307%22%2c%22Oid%22%3a%228d261fd5-be8f-44eb-b630-d5b230fc5ec3%22%7d" class="btn btn-primary px-3 py-3">Join Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="speaker-bio">Speaker Bio&lt;/h1>
&lt;p>Alexander Renz-Wieland is a PhD student working on large-scale machine learning
student in the Database Systems and Information Management (DIMA) group at
Technische Universität Berlin since September 2017. He is supervised by Volker
Markl and Rainer Gemulla (Universität Mannheim). Prior to his PhD, he completed
a M. Sc. Business Informatics with a specialization in Data and Web Science at
Universität Mannheim, with a semester at VU Amsterdam (with courses from CWI).
In his Master&amp;rsquo;s thesis, he worked on scalable sequential pattern mining.&lt;/p></description></item><item><title>Reading Group Session #2</title><link>https://sysml-icl.github.io/event/reading2/</link><pubDate>Thu, 23 Jun 2022 10:30:00 +0000</pubDate><guid>https://sysml-icl.github.io/event/reading2/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://teams.microsoft.com/l/meetup-join/19%3aLiP6Evh3ssJQ3g41q8vAsBNwwOFTzp7d_qq1y7oTo7A1%40thread.tacv2/1654597085925?context=%7b%22Tid%22%3a%222b897507-ee8c-4575-830b-4f8267c3d307%22%2c%22Oid%22%3a%228d261fd5-be8f-44eb-b630-d5b230fc5ec3%22%7d" class="btn btn-primary px-3 py-3">Join Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="papers">Papers&lt;/h1>
&lt;p>&lt;a href="https://arxiv.org/pdf/2205.06175.pdf?fs=e&amp;amp;s=cl" target="_blank" rel="noopener">A Generalist Agent&lt;/a>, arXiv'22&lt;/p>
&lt;p>&lt;strong>Paper Abstract:&lt;/strong>
Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato.&lt;/p>
&lt;h1 id="discussion-notes">Discussion Notes&lt;/h1>
&lt;p>Gato is a new take on how to achieve multi-task agents based on autoregressive modeling of sequence data.&lt;/p>
&lt;p>This paper was perhaps a bit out of scope for a SysML group, but we came up with a few future directions from the reading.&lt;/p>
&lt;h2 id="input-pipeline">Input pipeline&lt;/h2>
&lt;p>The input pipeline in Gato is far more complex than a conventional Supervised Learning input pipeline&lt;/p>
&lt;p>The inputs come from a large number of datasets (604, one per task) all which have large corpora.
Are available sampling mechanisms able to scale to these dimensions?&lt;/p>
&lt;p>Furthermore, on each iteration it requires tokenization, linearization and embedding of multi-modal inputs such that a batch containing a mix of tasks is formed.
While images are embedded using a ResNet block, text, actions and observations are embedded through a learned embedding.
Are existing libraries such as tf.data capable of such complex input pipelines? Can they maintain good throughput with these unbalanced tasks?&lt;/p>
&lt;h2 id="democratizing-fine-tuning">Democratizing Fine-Tuning&lt;/h2>
&lt;p>A common pattern nowadays seems to be that large research groups will pre-train extremely large general models (language models) and other groups will then fine-tune them to achieve good performance on a specific task (fine-tuning).
How is the workload of fine-tuning different from pre-training? Would it be possible to democratize fine-tuning such that it can be done on a laptop?&lt;/p>
&lt;h2 id="attention-memory-and-context-windows">Attention, Memory and Context Windows&lt;/h2>
&lt;p>To maintain a memory of the recent past, Gato uses a sliding window of recent observations and actions.
To achieve the long-term planning needed for general RL, an infinitely sized window would be needed.
However, growing the window size in current Transformer implementations would grow memory and compute requirements too.
Are Transformers the correct approach to RL? Could transformers be augmented with a long-term memory component? Or could their training systems be fundamentally altered such that they can handle larger windows without growing memory requirements?&lt;/p></description></item><item><title>Reading Group Session #1</title><link>https://sysml-icl.github.io/event/reading1/</link><pubDate>Thu, 09 Jun 2022 10:30:00 +0000</pubDate><guid>https://sysml-icl.github.io/event/reading1/</guid><description>&lt;ul class="cta-group">
&lt;li>
&lt;a href="https://teams.microsoft.com/l/meetup-join/19%3aLiP6Evh3ssJQ3g41q8vAsBNwwOFTzp7d_qq1y7oTo7A1%40thread.tacv2/1654597085925?context=%7b%22Tid%22%3a%222b897507-ee8c-4575-830b-4f8267c3d307%22%2c%22Oid%22%3a%228d261fd5-be8f-44eb-b630-d5b230fc5ec3%22%7d" class="btn btn-primary px-3 py-3">Join Session!&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h1 id="papers">Papers&lt;/h1>
&lt;p>Papers covered will be:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://ieeexplore.ieee.org/iel7/71/9497774/09472938.pdf" target="_blank" rel="noopener">vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training&lt;/a>, TPDS'21&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/pdf/2201.12023" target="_blank" rel="noopener">Alpa: Automating Inter-and Intra-Operator Parallelism for Distributed Deep Learning&lt;/a>, OSDI'22&lt;/li>
&lt;/ol>
&lt;h1 id="discussion-notes">Discussion Notes&lt;/h1>
&lt;p>In these discussion notes we attempt to summarize points made during the discussion on possible future directions.&lt;/p>
&lt;h2 id="vpipe">vPipe&lt;/h2>
&lt;h3 id="online-partitioning">Online partitioning&lt;/h3>
&lt;p>vPipes justification for the need for an online repartitioning algorithm is Neural Architecture Search (NAS).
Very few systems are using online partitioning nowadays. The question is, is there a need for them?
What are other motivating reasons for online partitioning?&lt;/p>
&lt;ul>
&lt;li>To deal with failures&lt;/li>
&lt;li>To support elasticity&lt;/li>
&lt;li>NAS&lt;/li>
&lt;li>Dynamic networks&lt;/li>
&lt;/ul>
&lt;p>In short, any source of dynamism in the training is justifiable.
What are other sources of dynamism in training?&lt;/p>
&lt;h3 id="pcie-usage">PCIe Usage&lt;/h3>
&lt;p>In vPipe PCIe is shared by swapping and inter-host activation communication.
The algorithm which decides the swap-recompute plan attempts to fill all the PCIe bandwidth but ignores activation communication traffic.
Is this optimal? Won&amp;rsquo;t this cause stalls by oversubscribing the PCIe bus?
Still, vPipe prioritizes inter-host activation communication.&lt;/p>
&lt;h2 id="alpa">Alpa&lt;/h2>
&lt;h3 id="device-meshes">Device Meshes&lt;/h3>
&lt;p>Alpa maps computations to a 2D mesh of devices. This seems to be due to the fact
that there are 2 layers in the device hierarchy, intra-host and inter-host,
where communication intra-host is faster than inter-host.
If there were a third level in this hierarchy, perhaps a 3D mesh of devices would make sense.&lt;/p>
&lt;h2 id="both-papers">Both papers&lt;/h2>
&lt;p>We noticed that both papers attempt to solve the NP-Complete task of parallelizing
a computational graph across several devices for optimal performance.
This task is too difficult to solve directly.
To tackle this, both papers use a decomposition approach, instead solving two subproblems optimally:&lt;/p>
&lt;ul>
&lt;li>Alpa first uses inter-op parallelism, then intra-op parallelism on each stage.&lt;/li>
&lt;li>vPipe first uses inter-op parallelism, then computes a swap/recompute plan for each stage.&lt;/li>
&lt;/ul>
&lt;p>Why can&amp;rsquo;t it be solved directly? Is it simply too large a search problem?
Are we losing something by not solving the original problem optimally?&lt;/p>
&lt;h3 id="heterogeneous-clusters">Heterogeneous Clusters&lt;/h3>
&lt;p>Heterogeneous clusters are a reality in several organizations which over time accumulate several generations of accelerators.
Furthermore, CPUs are a largely unused resource that is available.
Both papers, and other systems, generally target homogeneous clusters only.
We believe there is space for novel systems targeting Heterogeneous clusters, though the problem of partitioning and parallelizing becomes more difficult.&lt;/p></description></item></channel></rss>